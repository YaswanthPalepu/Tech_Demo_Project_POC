ðŸš€ Starting Enhanced Pipeline - Manual + Gap-Based AI Test Flow
===================================================================

ðŸŽ¯ Target Directory: /home/sigmoid/test-repos/clinic

ðŸ§¹ Cleaning previous coverage data...
âœ… Coverage data cleaned

ðŸ” Running detect_manual_tests.py on target repo...
ðŸ” Scanning repository for manual test directories in: /home/sigmoid/test-repos/clinic

ðŸ“Š Detection Result:
{
  "manual_tests_found": true,
  "manual_test_paths": [
    "/home/sigmoid/test-repos/clinic/tests"
  ],
  "test_files_count": 5,
  "test_dirs_detail": {
    "/home/sigmoid/test-repos/clinic/tests": [
      "/home/sigmoid/test-repos/clinic/tests/test_middleware.py",
      "/home/sigmoid/test-repos/clinic/tests/test_api.py",
      "/home/sigmoid/test-repos/clinic/tests/conftest.py",
      "/home/sigmoid/test-repos/clinic/tests/test_model.py",
      "/home/sigmoid/test-repos/clinic/tests/test_auth.py"
    ]
  }
}

ðŸ“ Manual Tests Found: True
ðŸ“‚ Test Paths: /home/sigmoid/test-repos/clinic/tests

âœ… Manual test cases detected. Running pytest with coverage analysis...

ðŸ“¦ Installing project dependencies...
Requirement already satisfied: fastapi==0.104.1 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 2)) (0.104.1)
Requirement already satisfied: uvicorn==0.24.0 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]==0.24.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 3)) (0.24.0)
Requirement already satisfied: pydantic==2.5.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 4)) (2.5.0)
Requirement already satisfied: torch==2.4.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (2.4.0)
Requirement already satisfied: transformers==4.35.2 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (4.35.2)
Requirement already satisfied: tokenizers==0.15.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 9)) (0.15.0)
Requirement already satisfied: accelerate==0.24.1 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 10)) (0.24.1)
Requirement already satisfied: python-jose==3.3.0 in ./venv/lib/python3.12/site-packages (from python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (3.3.0)
Requirement already satisfied: python-multipart==0.0.6 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 14)) (0.0.6)
Requirement already satisfied: prometheus-client==0.19.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 17)) (0.19.0)
Requirement already satisfied: aiofiles==23.2.1 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 20)) (23.2.1)
Requirement already satisfied: httpx==0.25.2 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 21)) (0.25.2)
Requirement already satisfied: psutil==5.9.6 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 24)) (5.9.6)
Requirement already satisfied: pytest==7.4.3 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 27)) (7.4.3)
Requirement already satisfied: pytest-asyncio==0.21.1 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 28)) (0.21.1)
Requirement already satisfied: pytest-cov==4.1.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 29)) (4.1.0)
Requirement already satisfied: black==23.10.1 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 30)) (23.10.1)
Requirement already satisfied: isort==5.12.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 31)) (5.12.0)
Requirement already satisfied: flake8==6.1.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 32)) (6.1.0)
Requirement already satisfied: mypy==1.7.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 33)) (1.7.0)
Requirement already satisfied: bandit==1.7.5 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (1.7.5)
Requirement already satisfied: safety==2.3.4 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 35)) (2.3.4)
Requirement already satisfied: python-dotenv==1.0.0 in ./venv/lib/python3.12/site-packages (from -r /home/sigmoid/test-repos/clinic/requirements.txt (line 38)) (1.0.0)
Requirement already satisfied: anyio<4.0.0,>=3.7.1 in ./venv/lib/python3.12/site-packages (from fastapi==0.104.1->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 2)) (3.7.1)
Requirement already satisfied: starlette<0.28.0,>=0.27.0 in ./venv/lib/python3.12/site-packages (from fastapi==0.104.1->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 2)) (0.27.0)
Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.12/site-packages (from fastapi==0.104.1->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 2)) (4.15.0)
Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic==2.5.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 4)) (0.7.0)
Requirement already satisfied: pydantic-core==2.14.1 in ./venv/lib/python3.12/site-packages (from pydantic==2.5.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 4)) (2.14.1)
Requirement already satisfied: click>=7.0 in ./venv/lib/python3.12/site-packages (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 3)) (8.3.0)
Requirement already satisfied: h11>=0.8 in ./venv/lib/python3.12/site-packages (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 3)) (0.16.0)
Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (3.20.0)
Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (1.14.0)
Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (3.5)
Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (3.1.6)
Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (2025.10.0)
Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (80.9.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (12.1.105)
Requirement already satisfied: triton==3.0.0 in ./venv/lib/python3.12/site-packages (from torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (3.0.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (0.36.0)
Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (2.3.4)
Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (25.0)
Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (6.0.3)
Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (2025.11.3)
Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (2.32.5)
Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (0.6.2)
Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.12/site-packages (from transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (4.67.1)
Requirement already satisfied: ecdsa!=0.15 in ./venv/lib/python3.12/site-packages (from python-jose==3.3.0->python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (0.19.1)
Requirement already satisfied: rsa in ./venv/lib/python3.12/site-packages (from python-jose==3.3.0->python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (4.9.1)
Requirement already satisfied: pyasn1 in ./venv/lib/python3.12/site-packages (from python-jose==3.3.0->python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (0.6.1)
Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx==0.25.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 21)) (2025.10.5)
Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx==0.25.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 21)) (1.0.9)
Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx==0.25.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 21)) (3.11)
Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx==0.25.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 21)) (1.3.1)
Requirement already satisfied: iniconfig in ./venv/lib/python3.12/site-packages (from pytest==7.4.3->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 27)) (2.3.0)
Requirement already satisfied: pluggy<2.0,>=0.12 in ./venv/lib/python3.12/site-packages (from pytest==7.4.3->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 27)) (1.6.0)
Requirement already satisfied: coverage>=5.2.1 in ./venv/lib/python3.12/site-packages (from coverage[toml]>=5.2.1->pytest-cov==4.1.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 29)) (7.11.3)
Requirement already satisfied: mypy-extensions>=0.4.3 in ./venv/lib/python3.12/site-packages (from black==23.10.1->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 30)) (1.1.0)
Requirement already satisfied: pathspec>=0.9.0 in ./venv/lib/python3.12/site-packages (from black==23.10.1->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 30)) (0.12.1)
Requirement already satisfied: platformdirs>=2 in ./venv/lib/python3.12/site-packages (from black==23.10.1->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 30)) (4.5.0)
Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in ./venv/lib/python3.12/site-packages (from flake8==6.1.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 32)) (0.7.0)
Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in ./venv/lib/python3.12/site-packages (from flake8==6.1.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 32)) (2.11.1)
Requirement already satisfied: pyflakes<3.2.0,>=3.1.0 in ./venv/lib/python3.12/site-packages (from flake8==6.1.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 32)) (3.1.0)
Requirement already satisfied: GitPython>=1.0.1 in ./venv/lib/python3.12/site-packages (from bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (3.1.45)
Requirement already satisfied: stevedore>=1.20.0 in ./venv/lib/python3.12/site-packages (from bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (5.5.0)
Requirement already satisfied: rich in ./venv/lib/python3.12/site-packages (from bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (14.2.0)
Requirement already satisfied: dparse>=0.6.2 in ./venv/lib/python3.12/site-packages (from safety==2.3.4->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 35)) (0.6.4)
Requirement already satisfied: ruamel.yaml>=0.17.21 in ./venv/lib/python3.12/site-packages (from safety==2.3.4->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 35)) (0.18.16)
Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (12.9.86)
Requirement already satisfied: cryptography>=3.4.0 in ./venv/lib/python3.12/site-packages (from python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (46.0.3)
Requirement already satisfied: httptools>=0.5.0 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]==0.24.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 3)) (0.7.1)
Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]==0.24.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 3)) (0.22.1)
Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]==0.24.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 3)) (1.1.1)
Requirement already satisfied: websockets>=10.4 in ./venv/lib/python3.12/site-packages (from uvicorn[standard]==0.24.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 3)) (15.0.1)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (1.2.0)
Requirement already satisfied: cffi>=2.0.0 in ./venv/lib/python3.12/site-packages (from cryptography>=3.4.0->python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (2.0.0)
Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (2.23)
Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.12/site-packages (from ecdsa!=0.15->python-jose==3.3.0->python-jose[cryptography]==3.3.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 13)) (1.10.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.12/site-packages (from GitPython>=1.0.1->bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (4.0.12)
Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.1->bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (5.0.2)
Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./venv/lib/python3.12/site-packages (from ruamel.yaml>=0.17.21->safety==2.3.4->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 35)) (0.2.14)
Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (3.0.3)
Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (3.4.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->transformers==4.35.2->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 8)) (2.5.0)
Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.12/site-packages (from rich->bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (4.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.12/site-packages (from rich->bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (2.19.2)
Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->bandit==1.7.5->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 34)) (0.1.2)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch==2.4.0->-r /home/sigmoid/test-repos/clinic/requirements.txt (line 7)) (1.3.0)

ðŸ“‚ Copying manual tests to local folder: ./tests/manual

âœ… Manual test files copied to ./tests/manual
ðŸ“„ Files:
./tests/manual/test_middleware.py
./tests/manual/test_api.py
./tests/manual/test_model.py
./tests/manual/test_auth.py

ðŸ§ª Running manual tests from local directory with coverage analysis: ./tests/manual

============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-7.4.3, pluggy-1.6.0 -- /home/sigmoid/TECH_DEMO/new-tech-demo/venv/bin/python3
cachedir: .pytest_cache
metadata: {'Python': '3.12.3', 'Platform': 'Linux-6.14.0-33-generic-x86_64-with-glibc2.39', 'Packages': {'pytest': '7.4.3', 'pluggy': '1.6.0'}, 'Plugins': {'html': '4.1.1', 'django': '4.11.1', 'asyncio': '0.21.1', 'mock': '3.15.1', 'anyio': '3.7.1', 'metadata': '3.1.1', 'cov': '4.1.0'}}
rootdir: /home/sigmoid/TECH_DEMO/new-tech-demo
configfile: pytest.ini
plugins: html-4.1.1, django-4.11.1, asyncio-0.21.1, mock-3.15.1, anyio-3.7.1, metadata-3.1.1, cov-4.1.0
asyncio: mode=Mode.AUTO
collecting ... collected 88 items

tests/manual/test_api.py::TestHealthEndpoint::test_health_check_success PASSED [  1%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_success PASSED [  2%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_empty_sentence PASSED [  3%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_various_sentences[The patient denies chest pain.] PASSED [  4%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_various_sentences[He has a history of hypertension.] PASSED [  5%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_various_sentences[No signs of pneumonia were observed.] PASSED [  6%]
tests/manual/test_api.py::TestBatchPredictionEndpoint::test_batch_predict_success PASSED [  7%]
tests/manual/test_api.py::TestBatchPredictionEndpoint::test_batch_predict_empty_list PASSED [  9%]
tests/manual/test_api.py::TestRootEndpoint::test_root_endpoint PASSED    [ 10%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_conditional PASSED [ 11%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_uncertainty PASSED [ 12%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_no_rule PASSED [ 13%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_multiple_sentences PASSED [ 14%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_conditional_phrases_positive PASSED [ 15%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_conditional_phrases_negative PASSED [ 17%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_uncertainty_phrases_positive PASSED [ 18%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_uncertainty_phrases_negative PASSED [ 19%]
tests/manual/test_api.py::TestEnhancedPredictionEndpoints::test_predict_with_hybrid_pipeline PASSED [ 20%]
tests/manual/test_api.py::TestEnhancedPredictionEndpoints::test_batch_predict_with_hybrid_pipeline PASSED [ 21%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_init_no_api_keys PASSED  [ 22%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_init_with_api_keys PASSED [ 23%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_init_with_whitespace_api_keys PASSED [ 25%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_verify_key_no_keys_required PASSED [ 26%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_verify_key_valid PASSED  [ 27%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_verify_key_invalid PASSED [ 28%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_health_endpoint FAILED [ 29%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_root_endpoint PASSED [ 30%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_metrics_endpoint PASSED [ 31%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_no_keys_required FAILED [ 32%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_missing_from_request FAILED [ 34%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_invalid FAILED [ 35%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_bearer FAILED [ 36%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_header FAILED [ 37%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_query_param FAILED [ 38%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_logging_invalid_key FAILED [ 39%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_multiple_keys PASSED [ 40%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_empty_key_string PASSED [ 42%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_whitespace_only PASSED [ 43%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_special_characters PASSED [ 44%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_case_sensitive PASSED [ 45%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_init PASSED [ 46%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_init_with_csp PASSED [ 47%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_dispatch_no_csp_http PASSED [ 48%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_dispatch_with_csp_https PASSED [ 50%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_init PASSED [ 51%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_get_client_id_with_x_forwarded_for PASSED [ 52%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_get_client_id_with_client PASSED [ 53%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_get_client_id_unknown PASSED [ 54%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_dispatch_health_endpoint PASSED [ 55%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_dispatch_under_limit PASSED [ 56%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_dispatch_over_limit PASSED [ 57%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_init PASSED [ 59%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_get_client_id_with_x_forwarded_for PASSED [ 60%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_get_client_id_with_client PASSED [ 61%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_get_client_id_unknown PASSED [ 62%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_dispatch_success PASSED [ 63%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_dispatch_with_exception FAILED [ 64%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_init PASSED [ 65%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_dispatch_success PASSED [ 67%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_dispatch_error PASSED [ 68%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_dispatch_exception PASSED [ 69%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_init PASSED [ 70%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_is_loaded_not_loaded PASSED [ 71%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_is_loaded_after_init PASSED [ 72%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_is_loaded_no_model PASSED [ 73%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_device_cuda_available PASSED [ 75%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_device_cuda_not_available PASSED [ 76%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_success FAILED [ 77%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_tokenizer_failure PASSED [ 78%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_model_failure PASSED [ 79%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_not_loaded PASSED [ 80%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_not_loaded PASSED [ 81%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_success FAILED [ 82%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_pipeline_error PASSED [ 84%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_success PASSED [ 85%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_list_result PASSED [ 86%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_nested_list_result PASSED [ 87%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_unexpected_result_type PASSED [ 88%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_success FAILED [ 89%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_success PASSED [ 90%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_single_result PASSED [ 92%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_get_model_info PASSED [ 93%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_get_model_info_cuda_available PASSED [ 94%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_empty_result PASSED [ 95%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_none_result PASSED [ 96%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_empty_results PASSED [ 97%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_mixed_result_types PASSED [ 98%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_unknown_label PASSED [100%]

=================================== FAILURES ===================================
_____________ TestVerifyAPIKey.test_verify_api_key_health_endpoint _____________

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d6523f50>
auth_client = <starlette.testclient.TestClient object at 0x79800bd9c1a0>

    def test_verify_api_key_health_endpoint(self, auth_client):
        """Test that health endpoint doesn't require API key"""
        response = auth_client.get("/health")
>       assert response.status_code == 200
E       assert 503 == 200
E        +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:55: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    app.main:main.py:229 Health check failed:
____________ TestVerifyAPIKey.test_verify_api_key_no_keys_required _____________

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d6528b00>
auth_client = <starlette.testclient.TestClient object at 0x79800bda2f90>

    def test_verify_api_key_no_keys_required(self, auth_client):
        """Test endpoints when no API keys are required"""
        with patch.dict(os.environ, {"API_KEYS": "", "REQUIRE_API_KEY": "false"}):
            response = auth_client.get("/model/info")
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:71: AssertionError
__________ TestVerifyAPIKey.test_verify_api_key_missing_from_request ___________

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d6528e60>
auth_client = <starlette.testclient.TestClient object at 0x79800bf856d0>

    def test_verify_api_key_missing_from_request(self, auth_client):
        """Test API key verification when key is missing"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get("/model/info")
>           assert response.status_code == 401
E           assert 503 == 401
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:79: AssertionError
_________________ TestVerifyAPIKey.test_verify_api_key_invalid _________________

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d65291c0>
auth_client = <starlette.testclient.TestClient object at 0x79800bb11fa0>

    def test_verify_api_key_invalid(self, auth_client):
        """Test API key verification with invalid key"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get(
                "/model/info", headers={"Authorization": "Bearer invalid_key"}
            )
>           assert response.status_code == 401
E           assert 503 == 401
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:91: AssertionError
______________ TestVerifyAPIKey.test_verify_api_key_valid_bearer _______________

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d6529580>
auth_client = <starlette.testclient.TestClient object at 0x79800bb26c60>

    def test_verify_api_key_valid_bearer(self, auth_client):
        """Test API key verification with valid Bearer token"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get(
                "/model/info", headers={"Authorization": "Bearer test_key"}
            )
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:103: AssertionError
______________ TestVerifyAPIKey.test_verify_api_key_valid_header _______________

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d6529820>
auth_client = <starlette.testclient.TestClient object at 0x79800bb1aab0>

    def test_verify_api_key_valid_header(self, auth_client):
        """Test API key verification with valid X-API-Key header"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get("/model/info", headers={"X-API-Key": "test_key"})
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:111: AssertionError
____________ TestVerifyAPIKey.test_verify_api_key_valid_query_param ____________

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d6523ef0>
auth_client = <starlette.testclient.TestClient object at 0x79800bb0ef60>

    def test_verify_api_key_valid_query_param(self, auth_client):
        """Test API key verification with valid query parameter"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get("/model/info?api_key=test_key")
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:119: AssertionError
___________ TestVerifyAPIKey.test_verify_api_key_logging_invalid_key ___________

self = <MagicMock name='logger.warning' id='133590858927472'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'warning' to have been called.

/usr/lib/python3.12/unittest/mock.py:913: AssertionError

During handling of the above exception, another exception occurred:

self = <manual.test_auth.TestVerifyAPIKey object at 0x7980d65237d0>

    def test_verify_api_key_logging_invalid_key(self):
        """Test that invalid API key attempts are logged"""
        # Standard library imports
        from unittest.mock import Mock
    
        from app.auth import verify_api_key
    
        with patch.dict(
            os.environ, {"API_KEYS": "valid_key", "REQUIRE_API_KEY": "true"}
        ), patch("app.auth.logger") as mock_logger:
            mock_request = Mock()
            mock_request.url.path = "/api/test"
            mock_request.client = Mock()
            mock_request.client.host = "192.168.1.1"
            mock_request.headers = {}
            mock_request.query_params = {}
    
            # This should raise an exception and log the invalid attempt
            try:
                verify_api_key(mock_request, None)
            except Exception:
                pass
    
            # Verify that warning was logged for invalid key attempt
>           mock_logger.warning.assert_called()
E           AssertionError: Expected 'warning' to have been called.

tests/manual/test_auth.py:145: AssertionError
__________ TestRequestLoggingMiddleware.test_dispatch_with_exception ___________

request = <Mock id='133590858976672'>

    async def failing_call_next(request):
>       raise Exception("Test error")
E       Exception: Test error

tests/manual/test_middleware.py:248: Exception

During handling of the above exception, another exception occurred:

self = <app.middleware.RequestLoggingMiddleware object at 0x79800bb1d730>
request = <Mock id='133590858976672'>
call_next = <function TestRequestLoggingMiddleware.test_dispatch_with_exception.<locals>.failing_call_next at 0x79800b058ea0>

    async def dispatch(
        self, request: Request, call_next: Callable[[Request], Awaitable[Response]]
    ) -> Response:
        start_time = time.time()
        request_id = request.headers.get(
            "X-Request-ID", f"req-{int(start_time * 1000)}"
        )
    
        logger.info(
            json.dumps(
                {
                    "event": "request_started",
                    "request_id": request_id,
                    "method": request.method,
                    "path": request.url.path,
                    "client_ip": self.get_client_id(request),
                    "timestamp": start_time,
                }
            )
        )
    
        try:
            response = await call_next(request)
    
            duration = time.time() - start_time
            logger.info(
                json.dumps(
                    {
                        "event": "request_completed",
                        "request_id": request_id,
                        "status_code": response.status_code,
                        "duration_ms": duration * 1000,
                        "timestamp": time.time(),
                    }
                )
            )
    
            response.headers["X-Request-ID"] = request_id
            return response
    
        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                json.dumps(
                    {
                        "event": "request_failed",
                        "request_id": request_id,
                        "error": str(e),
                        "duration_ms": duration * 1000,
>                       "timestamp": time.time(),
                    }
                )
            )

../../test-repos/clinic/app/middleware.py:155: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1134: in __call__
    return self._mock_call(*args, **kwargs)
/usr/lib/python3.12/unittest/mock.py:1138: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='time' id='133590858979696'>, args = (), kwargs = {}
effect = <list_iterator object at 0x79800bb1c490>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/usr/lib/python3.12/unittest/mock.py:1195: StopIteration

The above exception was the direct cause of the following exception:

self = <manual.test_middleware.TestRequestLoggingMiddleware object at 0x7980d624fe90>
middleware = <app.middleware.RequestLoggingMiddleware object at 0x79800bb1d730>

    @pytest.mark.asyncio
    async def test_dispatch_with_exception(self, middleware):
        """Test request dispatch with exception"""
        mock_request = Mock()
        mock_request.method = "POST"
        mock_request.url.path = "/api/test"
        mock_request.headers = {}
        mock_request.client = None
    
        async def failing_call_next(request):
            raise Exception("Test error")
    
        with patch("time.time", side_effect=[1000.0, 1000.3]), patch(
            "app.middleware.logger"
        ) as mock_logger:
            with pytest.raises(Exception, match="Test error"):
>               await middleware.dispatch(mock_request, failing_call_next)
E               RuntimeError: coroutine raised StopIteration

tests/manual/test_middleware.py:254: RuntimeError

During handling of the above exception, another exception occurred:

self = <manual.test_middleware.TestRequestLoggingMiddleware object at 0x7980d624fe90>
middleware = <app.middleware.RequestLoggingMiddleware object at 0x79800bb1d730>

    @pytest.mark.asyncio
    async def test_dispatch_with_exception(self, middleware):
        """Test request dispatch with exception"""
        mock_request = Mock()
        mock_request.method = "POST"
        mock_request.url.path = "/api/test"
        mock_request.headers = {}
        mock_request.client = None
    
        async def failing_call_next(request):
            raise Exception("Test error")
    
        with patch("time.time", side_effect=[1000.0, 1000.3]), patch(
            "app.middleware.logger"
        ) as mock_logger:
>           with pytest.raises(Exception, match="Test error"):
E           AssertionError: Regex pattern did not match.
E            Regex: 'Test error'
E            Input: 'coroutine raised StopIteration'

tests/manual/test_middleware.py:253: AssertionError
______________ TestClinicalAssertionModel.test_load_model_success ______________

self = <manual.test_model.TestClinicalAssertionModel object at 0x79800c1dcb90>
mock_cuda = <MagicMock name='is_available' id='133590861229248'>
mock_pipeline = <MagicMock name='TextClassificationPipeline' id='133590849551392'>
mock_model_class = <MagicMock name='from_pretrained' id='133590858922368'>
mock_tokenizer = <MagicMock name='from_pretrained' id='133590861597776'>
model = <app.model.ClinicalAssertionModel object at 0x79800bb0d580>

    @pytest.mark.asyncio
    @patch("app.model.AutoTokenizer.from_pretrained")
    @patch("app.model.AutoModelForSequenceClassification.from_pretrained")
    @patch("app.model.TextClassificationPipeline")
    @patch("torch.cuda.is_available")
    async def test_load_model_success(
        self, mock_cuda, mock_pipeline, mock_model_class, mock_tokenizer, model
    ):
        """Test successful model loading"""
        mock_cuda.return_value = False
    
        # Mock the model and tokenizer
        mock_model_instance = Mock()
        mock_model_class.return_value = mock_model_instance
        mock_tokenizer_instance = Mock()
        mock_tokenizer.return_value = mock_tokenizer_instance
        mock_pipeline_instance = Mock()
        mock_pipeline.return_value = mock_pipeline_instance
    
        await model.load_model()
    
        assert model.tokenizer == mock_tokenizer_instance
>       assert model.model == mock_model_instance
E       AssertionError: assert <Mock name='from_pretrained().to().to()' id='133590861620928'> == <Mock name='from_pretrained()' id='133590861231648'>
E        +  where <Mock name='from_pretrained().to().to()' id='133590861620928'> = <app.model.ClinicalAssertionModel object at 0x79800bb0d580>.model

tests/manual/test_model.py:82: AssertionError
_______________ TestClinicalAssertionModel.test_predict_success ________________

self = <manual.test_model.TestClinicalAssertionModel object at 0x79800c1e2fc0>
mock_loop = <MagicMock name='get_event_loop' id='133590858960720'>
model = <app.model.ClinicalAssertionModel object at 0x79800bb18560>

    @pytest.mark.asyncio
    @patch("asyncio.get_event_loop")
    async def test_predict_success(self, mock_loop, model):
        """Test successful prediction"""
        # Setup model as loaded
        model._loaded = True
        model.model = Mock()
        model.pipeline = Mock()
    
        # Mock the pipeline result
        mock_result = {"label": "LABEL_0", "score": 0.95}
        model.pipeline.return_value = [mock_result]
    
        # Mock asyncio loop
        mock_loop_instance = Mock()
        mock_loop.return_value = mock_loop_instance
        mock_loop_instance.run_in_executor = AsyncMock(return_value=mock_result)
    
        result = await model.predict("test sentence")
    
>       assert result == {"label": "PRESENT", "score": 0.95}
E       AssertionError: assert {'label': 'LA...'score': 0.95} == {'label': 'PR...'score': 0.95}
E         Omitting 1 identical items, use -vv to show
E         Differing items:
E         {'label': 'LABEL_0'} != {'label': 'PRESENT'}
E         Full diff:
E         - {'label': 'PRESENT', 'score': 0.95}
E         ?            ^^ ^^^^
E         + {'label': 'LABEL_0', 'score': 0.95}
E         ?            ^^^ ^^^

tests/manual/test_model.py:145: AssertionError
____________ TestClinicalAssertionModel.test_predict_batch_success _____________

self = <manual.test_model.TestClinicalAssertionModel object at 0x79800c1ed6d0>
mock_loop = <MagicMock name='get_event_loop' id='133590858935584'>
model = <app.model.ClinicalAssertionModel object at 0x79800bb13a40>

    @pytest.mark.asyncio
    @patch("asyncio.get_event_loop")
    async def test_predict_batch_success(self, mock_loop, model):
        """Test successful batch prediction"""
        # Setup model as loaded
        model._loaded = True
        model.model = Mock()
        model.pipeline = Mock()
    
        # Mock batch results
        mock_results = [
            [{"label": "LABEL_0", "score": 0.95}],
            [{"label": "LABEL_1", "score": 0.87}],
        ]
        model.pipeline.return_value = mock_results
    
        # Mock asyncio loop
        mock_loop_instance = Mock()
        mock_loop.return_value = mock_loop_instance
        mock_loop_instance.run_in_executor = AsyncMock(return_value=mock_results)
    
        result = await model.predict_batch(["sentence 1", "sentence 2"])
    
        expected = [
            {"label": "PRESENT", "score": 0.95},
            {"label": "ABSENT", "score": 0.87},
        ]
>       assert result == expected
E       AssertionError: assert [[{'label': '...core': 0.87}]] == [{'label': 'P...score': 0.87}]
E         At index 0 diff: [{'label': 'LABEL_0', 'score': 0.95}] != {'label': 'PRESENT', 'score': 0.95}
E         Full diff:
E         - [{'label': 'PRESENT', 'score': 0.95}, {'label': 'ABSENT', 'score': 0.87}]
E         ?             ^^ ^^^^                                - ^^
E         + [[{'label': 'LABEL_0', 'score': 0.95}], [{'label': 'LABEL_1', 'score': 0.87}]]
E         ? +            ^^^ ^^^                 +  +           +   ^^^                  +

tests/manual/test_model.py:237: AssertionError
=============================== warnings summary ===============================
venv/lib/python3.12/site-packages/transformers/utils/generic.py:441
  /home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
    _torch_pytree._register_pytree_node(

venv/lib/python3.12/site-packages/transformers/utils/generic.py:309
  /home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
    _torch_pytree._register_pytree_node(

tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_logging_invalid_key
  /home/sigmoid/TECH_DEMO/new-tech-demo/tests/manual/test_auth.py:140: RuntimeWarning: coroutine 'verify_api_key' was never awaited
    verify_api_key(mock_request, None)
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform linux, python 3.12.3-final-0 -----------
Name                                                Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------------------------------------
/home/sigmoid/test-repos/clinic/app/__init__.py         1      0      0      0   100%
/home/sigmoid/test-repos/clinic/app/auth.py            39     15     18      2    53%   42, 47-70
/home/sigmoid/test-repos/clinic/app/main.py           154     40     16      5    72%   73-100, 160, 176-178, 257, 277-278, 333-336, 358, 365, 432-437, 454-457, 536-542
/home/sigmoid/test-repos/clinic/app/middleware.py      92      1     14      0    99%   159
/home/sigmoid/test-repos/clinic/app/model.py           82      3     14      1    96%   45->48, 117-119
/home/sigmoid/test-repos/clinic/app/schemas.py         70      4     10      4    90%   37, 86, 90, 94
/home/sigmoid/test-repos/clinic/app/utils.py           49     10     12      3    79%   15-28, 39, 55, 104->108
-----------------------------------------------------------------------------------------------
TOTAL                                                 487     73     84     15    82%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml

=========================== short test summary info ============================
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_health_endpoint
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_no_keys_required
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_missing_from_request
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_invalid
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_bearer
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_header
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_query_param
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_logging_invalid_key
FAILED tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_dispatch_with_exception
FAILED tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_success
FAILED tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_success
FAILED tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_success
================== 12 failed, 76 passed, 3 warnings in 18.47s ==================
ðŸ“Š Coverage report generated
Name                                                Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------------------------------------
/home/sigmoid/test-repos/clinic/app/__init__.py         1      0      0      0   100%
/home/sigmoid/test-repos/clinic/app/auth.py            39     15     18      2    53%   42, 47-70
/home/sigmoid/test-repos/clinic/app/main.py           157     42     18      6    71%   73-100, 160, 176-178, 257, 277-278, 333-336, 358, 365, 432-437, 454-457, 536-542, 558-559
/home/sigmoid/test-repos/clinic/app/middleware.py      92      1     14      0    99%   159
/home/sigmoid/test-repos/clinic/app/model.py           82      3     14      1    96%   45->48, 117-119
/home/sigmoid/test-repos/clinic/app/schemas.py         70      4     10      4    90%   37, 86, 90, 94
/home/sigmoid/test-repos/clinic/app/utils.py           49     10     12      3    79%   15-28, 39, 55, 104->108
-----------------------------------------------------------------------------------------------
TOTAL                                                 490     75     86     16    82%

âœ… Pytest completed for manual tests.

âœ… Manual Test Coverage: 85.01%

ðŸ“Š Coverage Summary:
  app/__init__.py: 100.0%
  app/auth.py: 61.5%
  app/main.py: 74.0%
  app/middleware.py: 98.9%
  app/model.py: 96.3%
  app/schemas.py: 94.3%
  app/utils.py: 79.6%

= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80
COVERAGE ANALYSIS PHASE
= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80
hello
ðŸ” Analyzing coverage gaps...
ðŸ” Analyzing coverage gaps...
================================================================================
COVERAGE GAP ANALYSIS REPORT
================================================================================

Overall Coverage: 85.01%
Total Statements: 487
Covered Statements: 414
Missing Statements: 73
AI Generation Needed: YES

FILES WITH COVERAGE GAPS:
--------------------------------------------------------------------------------

ðŸ“ app/auth.py
   Coverage: 61.54%
   Missing Lines: 15
   Uncovered: 42, 47, 49-50, 52-53, 55-56, 58-59, 63-66, 70

ðŸ“ app/main.py
   Coverage: 74.03%
   Missing Lines: 40
   Uncovered: 73-75, 77, 79-80, 83-84, 86-87, 89-91, 93, 96-97, 99-100, 160, 176, 178, 257, 277-278, 333-336, 358, 365, 432-433, 436-437, 454-455, 457, 536, 540, 542

ðŸ“ app/middleware.py
   Coverage: 98.91%
   Missing Lines: 1
   Uncovered: 159

ðŸ“ app/model.py
   Coverage: 96.34%
   Missing Lines: 3
   Uncovered: 117-119

ðŸ“ app/schemas.py
   Coverage: 94.29%
   Missing Lines: 4
   Uncovered: 37, 86, 90, 94

ðŸ“ app/utils.py
   Coverage: 79.59%
   Missing Lines: 10
   Uncovered: 15-18, 20, 26-28, 39, 55



================================================================================
âœ… Coverage gap analysis saved to: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json

âš ï¸  Coverage is below 90% (85.01%)
ðŸ¤– AI test generation recommended for uncovered code

âš ï¸  Coverage is below 90%
ðŸ¤– Initiating Gap-Based AI Test Generation...

= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80
GAP-BASED AI TEST GENERATION (Using Full AI Workflow)
= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80

Warning: postprocess import failed: cannot import name 'extract_python_only' from 'src.gen.postprocess' (/home/sigmoid/TECH_DEMO/new-tech-demo/src/gen/postprocess.py); using fallbacks
ðŸŽ¯ Gap-focused mode enabled via --coverage-mode argument
Found 14 Python files in target directory
Project structure: Universal compatibility enabled
UNIVERSAL analysis for ANY PROJECT STRUCTURE in: /home/sigmoid/test-repos/clinic
Analyzing 8 Python files in project...
[framework_manager] Detection error in django: 'str' object has no attribute 'get'
[framework_manager] Framework(s) detected: ['fastapi', 'universal'] -> selected: fastapi
UNIVERSAL ANALYSIS COMPLETE:
   Files analyzed: 8
   Functions: 42 (top-level)
   Nested Functions: 23
   Classes: 28
   Methods: 23
   Routes: 8
   FastAPI Routes: 10
   Properties: 0
   Async functions: 39
   Imports tracked: 104
   Django models: 0
   Serializers: 0
   Views/ViewSets: 0
   Forms: 0
   Admin: 0
   Project packages: 2
   Detected Framework: fastapi
Starting UNIVERSAL test generation with gap-focused coverage mode...
UNIVERSAL test generation for ANY PROJECT STRUCTURE...

ðŸŽ¯ GAP-FOCUSED MODE: Analyzing coverage gaps...

================================================================================
GAP-FOCUSED MODE ACTIVE
================================================================================
Filtering analysis to target only uncovered code...
âœ… Loaded coverage gaps analysis from: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json
   Current Coverage: 85.01%
   Uncovered Functions: 0
   Uncovered Classes: 0
   Files with Gaps: 6

ðŸŽ¯ Filtering analysis to focus on coverage gaps...

ðŸ“Š Gap-Focused Analysis Results:
   Original Functions: 42 â†’ Uncovered: 0
   Original Classes: 28 â†’ Uncovered: 0
   Original Methods: 23 â†’ Uncovered: 0
   Original Routes: 8 â†’ Uncovered: 8
   Total Reduction: 100.0% (focusing only on gaps)

âœ… Gap-focused analysis prepared
   Targeting 73 uncovered statements
================================================================================

âœ… Gap analysis complete: Targeting 0 uncovered functions, 0 uncovered classes, 0 uncovered methods
âœ… Successfully wrote: tests/generated/conftest.py
Created universal conftest: tests/generated/conftest.py
TESTGEN_FORCE environment variable: 'true'
ðŸš€ Force generation enabled - will regenerate all tests
Found 8 source files for force generation:
  - app/__init__.py
  - app/auth.py
  - app/main.py
  - app/middleware.py
  - app/model.py
  - app/schemas.py
  - app/utils.py
  - scripts/health-check.py
ðŸ§¹ Force mode: Cleaning up all existing generated tests
Cleaned up 0 existing test files
UNIVERSAL TARGET INCLUSION:
   Functions: 4 (including 4 nested)
   Classes: 0
   Methods: 0
   Routes: 18
   Project Packages: 2
Using universal targeting - all targets included
Analyzing required packages...
   auth: Local module (skipped pip install)
   middleware: Local module (skipped pip install)
   model: Local module (skipped pip install)
   schemas: Local module (skipped pip install)
   utils: Local module (skipped pip install)
Inferred 9 external packages: fastapi, httpx, prometheus_client, psutil, pydantic, starlette, torch, transformers, uvicorn
Installing 9 external packages...
Installing packages: fastapi, httpx, prometheus_client, psutil, pydantic, starlette, torch, transformers, uvicorn
   fastapi
   httpx
   prometheus_client
   psutil
   pydantic
   starlette
   torch
   transformers
   uvicorn
Successfully installed 9 packages.
UNIVERSAL COVERAGE TARGETS:
   Functions: 4
   Classes: 0
   Methods: 0
   Routes: 18
   Total Targets: 22
   Expected Coverage: Maximum
   Project Structure: Universal compatibility
Generating 1 UNIT test files for universal compatibility...
Generating unit test 1/1 for 4 targets
âœ… Loaded coverage gaps analysis from: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json
   Current Coverage: 85.01%
   Uncovered Functions: 0
   Uncovered Classes: 0
   Files with Gaps: 6
âœ… Loaded coverage gaps analysis from: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json
   Current Coverage: 85.01%
   Uncovered Functions: 0
   Uncovered Classes: 0
   Files with Gaps: 6
   ðŸ“Š Added 1691 chars of gap-focused context to prompt
âš ï¸ Syntax error in generated code for tests/generated/test_unit_20251113_172726_01.py: expected an indented block after 'if' statement on line 22 (<unknown>, line 25)
âœ… Fixed syntax errors in tests/generated/test_unit_20251113_172726_01.py
âœ… Successfully wrote: tests/generated/test_unit_20251113_172726_01.py
  test_unit_20251113_172726_01.py - 4 targets
Generating 1 INTEG test files for universal compatibility...
Generating integ test 1/1 for 18 targets
âœ… Loaded coverage gaps analysis from: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json
   Current Coverage: 85.01%
   Uncovered Functions: 0
   Uncovered Classes: 0
   Files with Gaps: 6
âœ… Loaded coverage gaps analysis from: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json
   Current Coverage: 85.01%
   Uncovered Functions: 0
   Uncovered Classes: 0
   Files with Gaps: 6
   ðŸ“Š Added 1691 chars of gap-focused context to prompt
âš ï¸ Syntax error in generated code for tests/generated/test_integ_20251113_172726_01.py: expected an indented block after 'if' statement on line 23 (<unknown>, line 26)
âœ… Fixed syntax errors in tests/generated/test_integ_20251113_172726_01.py
âœ… Successfully wrote: tests/generated/test_integ_20251113_172726_01.py
  test_integ_20251113_172726_01.py - 18 targets
Generating 1 E2E test files for universal compatibility...
Generating e2e test 1/1 for 18 targets
âœ… Loaded coverage gaps analysis from: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json
   Current Coverage: 85.01%
   Uncovered Functions: 0
   Uncovered Classes: 0
   Files with Gaps: 6
âœ… Loaded coverage gaps analysis from: /home/sigmoid/TECH_DEMO/new-tech-demo/coverage_gaps.json
   Current Coverage: 85.01%
   Uncovered Functions: 0
   Uncovered Classes: 0
   Files with Gaps: 6
   ðŸ“Š Added 1691 chars of gap-focused context to prompt
âš ï¸ Syntax error in generated code for tests/generated/test_e2e_20251113_172726_01.py: expected an indented block after 'if' statement on line 22 (<unknown>, line 25)
âœ… Fixed syntax errors in tests/generated/test_e2e_20251113_172726_01.py
âœ… Successfully wrote: tests/generated/test_e2e_20251113_172726_01.py
  test_e2e_20251113_172726_01.py - 18 targets
Updated test mapping for 8 source files
Generation completed: 3 test files for 8 source files
ðŸ“Š Updated test manifest: tests/generated/_manifest.json
UNIVERSAL GENERATION COMPLETE: 3 test files
Expected Coverage: Maximum with REAL IMPORTS
Universal Compatibility: ENABLED
Targets Covered: 22
Project Structure: 2 packages detected
UNIVERSAL TEST GENERATION SUCCESSFUL!
UNIVERSAL Results:
   Generated: 3 test files
   Coverage Mode: gap-focused
   Universal Compatibility: ENABLED
   Targets Covered: 101
   Project Structure: Universal handling enabled
Run UNIVERSAL Tests:
   Basic: python -m pytest ./tests/generated -v
   Coverage: python -m pytest ./tests/generated --cov=. --cov-report=html
   Universal: PYTHONPATH=/home/sigmoid/test-repos/clinic python -m pytest ./tests/generated
=== AI Test Generation Completed ===
ðŸ§© Total AI-generated test files: 3
./tests/generated/test_unit_20251113_172726_01.py
./tests/generated/test_e2e_20251113_172726_01.py
./tests/generated/test_integ_20251113_172726_01.py

âœ… Gap-based AI test generation completed successfully

= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80
RUNNING COMBINED TESTS (Manual + AI Generated)
= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80

ðŸ“¦ Installing project dependencies...
ðŸ§ª Running combined test suite...
============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-7.4.3, pluggy-1.6.0 -- /home/sigmoid/TECH_DEMO/new-tech-demo/venv/bin/python3
cachedir: .pytest_cache
django: version: 5.2.8
metadata: {'Python': '3.12.3', 'Platform': 'Linux-6.14.0-33-generic-x86_64-with-glibc2.39', 'Packages': {'pytest': '7.4.3', 'pluggy': '1.6.0'}, 'Plugins': {'html': '4.1.1', 'django': '4.11.1', 'asyncio': '0.21.1', 'mock': '3.15.1', 'anyio': '3.7.1', 'metadata': '3.1.1', 'cov': '4.1.0'}}
rootdir: /home/sigmoid/TECH_DEMO/new-tech-demo
configfile: pytest.ini
plugins: html-4.1.1, django-4.11.1, asyncio-0.21.1, mock-3.15.1, anyio-3.7.1, metadata-3.1.1, cov-4.1.0
asyncio: mode=Mode.AUTO
collecting ... collected 129 items

tests/generated/test_e2e_20251113_172726_01.py::test_service_status_contains_expected_fields PASSED [  0%]
tests/generated/test_e2e_20251113_172726_01.py::test_health_check_when_model_missing_returns_503_and_error_message FAILED [  1%]
tests/generated/test_e2e_20251113_172726_01.py::test_health_check_when_model_unloaded_reports_unhealthy_and_no_model_info PASSED [  2%]
tests/generated/test_e2e_20251113_172726_01.py::test_health_check_when_model_loaded_returns_model_info_and_system_metrics PASSED [  3%]
tests/generated/test_e2e_20251113_172726_01.py::test_metrics_endpoint_returns_prometheus_format PASSED [  3%]
tests/generated/test_e2e_20251113_172726_01.py::test_model_info_raises_503_when_model_not_loaded PASSED [  4%]
tests/generated/test_e2e_20251113_172726_01.py::test_model_info_returns_info_when_model_loaded FAILED [  5%]
tests/generated/test_e2e_20251113_172726_01.py::test_predict_assertion_503_when_model_not_loaded PASSED [  6%]
tests/generated/test_e2e_20251113_172726_01.py::test_predict_assertion_success_and_metrics_and_response_fields PASSED [  6%]
tests/generated/test_e2e_20251113_172726_01.py::test_predict_assertion_failure_in_model_triggers_500_and_handler PASSED [  7%]
tests/generated/test_e2e_20251113_172726_01.py::test_predict_batch_rejects_oversized_batch PASSED [  8%]
tests/generated/test_e2e_20251113_172726_01.py::test_predict_batch_success_returns_predictions_and_batch_size PASSED [  9%]
tests/generated/test_e2e_20251113_172726_01.py::test_predict_batch_failure_when_model_raises PASSED [ 10%]
tests/generated/test_e2e_20251113_172726_01.py::test_system_metrics_reflects_prediction_count_and_model_loaded PASSED [ 10%]
tests/generated/test_e2e_20251113_172726_01.py::test_root_returns_expected_metadata_and_status_initializing_and_healthy PASSED [ 11%]
tests/generated/test_e2e_20251113_172726_01.py::test_validate_sentence_various_inputs[normal-This is a test.-True] SKIPPED [ 12%]
tests/generated/test_e2e_20251113_172726_01.py::test_validate_sentence_various_inputs[empty--False] SKIPPED [ 13%]
tests/generated/test_e2e_20251113_172726_01.py::test_validate_sentence_various_inputs[none-None-False] SKIPPED [ 13%]
tests/generated/test_e2e_20251113_172726_01.py::test_validate_sentences_various_inputs[normal_batch-sentences0-2] SKIPPED [ 14%]
tests/generated/test_e2e_20251113_172726_01.py::test_validate_sentences_various_inputs[empty_batch-sentences1-0] SKIPPED [ 15%]
tests/generated/test_integ_20251113_172726_01.py::test_service_status_endpoint_contains_expected_fields PASSED [ 16%]
tests/generated/test_integ_20251113_172726_01.py::test_health_check_returns_503_when_model_not_loaded FAILED [ 17%]
tests/generated/test_integ_20251113_172726_01.py::test_model_info_raises_503_when_model_not_loaded PASSED [ 17%]
tests/generated/test_integ_20251113_172726_01.py::test_model_info_triggers_general_exception_handler_on_unexpected_error FAILED [ 18%]
tests/generated/test_integ_20251113_172726_01.py::test_predict_assertion_returns_503_when_model_missing PASSED [ 19%]
tests/generated/test_integ_20251113_172726_01.py::test_predict_assertion_success_happy_path_and_background_task PASSED [ 20%]
tests/generated/test_integ_20251113_172726_01.py::test_predict_batch_success_and_batch_size_limit PASSED [ 20%]
tests/generated/test_integ_20251113_172726_01.py::test_metrics_endpoint_returns_prometheus_text PASSED [ 21%]
tests/generated/test_integ_20251113_172726_01.py::test_root_endpoint_reflects_model_status[initializing] PASSED [ 22%]
tests/generated/test_integ_20251113_172726_01.py::test_root_endpoint_reflects_model_status[healthy] PASSED [ 23%]
tests/generated/test_integ_20251113_172726_01.py::test_system_metrics_with_and_without_model PASSED [ 24%]
tests/generated/test_integ_20251113_172726_01.py::test_schemas_validators_trigger_on_invalid_input_and_accept_valid_input PASSED [ 24%]
tests/generated/test_integ_20251113_172726_01.py::test_http_exception_handler_increments_metrics_and_returns_structure PASSED [ 25%]
tests/generated/test_unit_20251113_172726_01.py::test_predict_batch_success_and_response_shape PASSED [ 26%]
tests/generated/test_unit_20251113_172726_01.py::test_predict_batch_model_not_loaded_raises PASSED [ 27%]
tests/generated/test_unit_20251113_172726_01.py::test_predict_batch_exceeds_max_batch_size PASSED [ 27%]
tests/generated/test_unit_20251113_172726_01.py::test_validate_sentence_various_inputs SKIPPED [ 28%]
tests/generated/test_unit_20251113_172726_01.py::test_validate_sentences_various_inputs SKIPPED [ 29%]
tests/generated/test_unit_20251113_172726_01.py::test_middleware_dispatch_variants PASSED [ 30%]
tests/generated/test_unit_20251113_172726_01.py::test_model_predict_batch_method_monkeypatched_init PASSED [ 31%]
tests/generated/test_unit_20251113_172726_01.py::test_http_and_general_exception_handlers PASSED [ 31%]
tests/manual/test_api.py::TestHealthEndpoint::test_health_check_success PASSED [ 32%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_success PASSED [ 33%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_empty_sentence PASSED [ 34%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_various_sentences[The patient denies chest pain.] PASSED [ 34%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_various_sentences[He has a history of hypertension.] PASSED [ 35%]
tests/manual/test_api.py::TestPredictionEndpoint::test_predict_various_sentences[No signs of pneumonia were observed.] PASSED [ 36%]
tests/manual/test_api.py::TestBatchPredictionEndpoint::test_batch_predict_success PASSED [ 37%]
tests/manual/test_api.py::TestBatchPredictionEndpoint::test_batch_predict_empty_list PASSED [ 37%]
tests/manual/test_api.py::TestRootEndpoint::test_root_endpoint PASSED    [ 38%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_conditional PASSED [ 39%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_uncertainty PASSED [ 40%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_no_rule PASSED [ 41%]
tests/manual/test_api.py::TestHybridPipeline::test_apply_hybrid_pipeline_multiple_sentences PASSED [ 41%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_conditional_phrases_positive PASSED [ 42%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_conditional_phrases_negative PASSED [ 43%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_uncertainty_phrases_positive PASSED [ 44%]
tests/manual/test_api.py::TestUtilityFunctions::test_detect_uncertainty_phrases_negative PASSED [ 44%]
tests/manual/test_api.py::TestEnhancedPredictionEndpoints::test_predict_with_hybrid_pipeline PASSED [ 45%]
tests/manual/test_api.py::TestEnhancedPredictionEndpoints::test_batch_predict_with_hybrid_pipeline PASSED [ 46%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_init_no_api_keys PASSED  [ 47%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_init_with_api_keys PASSED [ 48%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_init_with_whitespace_api_keys PASSED [ 48%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_verify_key_no_keys_required PASSED [ 49%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_verify_key_valid PASSED  [ 50%]
tests/manual/test_auth.py::TestAPIKeyAuth::test_verify_key_invalid PASSED [ 51%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_health_endpoint FAILED [ 51%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_root_endpoint PASSED [ 52%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_metrics_endpoint PASSED [ 53%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_no_keys_required FAILED [ 54%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_missing_from_request FAILED [ 55%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_invalid FAILED [ 55%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_bearer FAILED [ 56%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_header FAILED [ 57%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_query_param FAILED [ 58%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_logging_invalid_key FAILED [ 58%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_multiple_keys PASSED [ 59%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_empty_key_string PASSED [ 60%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_whitespace_only PASSED [ 61%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_special_characters PASSED [ 62%]
tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_case_sensitive PASSED [ 62%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_init PASSED [ 63%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_init_with_csp PASSED [ 64%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_dispatch_no_csp_http PASSED [ 65%]
tests/manual/test_middleware.py::TestSecurityHeadersMiddleware::test_dispatch_with_csp_https PASSED [ 65%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_init PASSED [ 66%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_get_client_id_with_x_forwarded_for PASSED [ 67%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_get_client_id_with_client PASSED [ 68%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_get_client_id_unknown PASSED [ 68%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_dispatch_health_endpoint PASSED [ 69%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_dispatch_under_limit PASSED [ 70%]
tests/manual/test_middleware.py::TestRateLimitMiddleware::test_dispatch_over_limit PASSED [ 71%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_init PASSED [ 72%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_get_client_id_with_x_forwarded_for PASSED [ 72%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_get_client_id_with_client PASSED [ 73%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_get_client_id_unknown PASSED [ 74%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_dispatch_success PASSED [ 75%]
tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_dispatch_with_exception FAILED [ 75%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_init PASSED [ 76%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_dispatch_success PASSED [ 77%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_dispatch_error PASSED [ 78%]
tests/manual/test_middleware.py::TestMetricsMiddleware::test_dispatch_exception PASSED [ 79%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_init PASSED [ 79%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_is_loaded_not_loaded PASSED [ 80%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_is_loaded_after_init PASSED [ 81%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_is_loaded_no_model PASSED [ 82%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_device_cuda_available PASSED [ 82%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_device_cuda_not_available PASSED [ 83%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_success FAILED [ 84%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_tokenizer_failure PASSED [ 85%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_model_failure PASSED [ 86%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_not_loaded PASSED [ 86%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_not_loaded PASSED [ 87%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_success FAILED [ 88%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_pipeline_error PASSED [ 89%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_success PASSED [ 89%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_list_result PASSED [ 90%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_nested_list_result PASSED [ 91%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_unexpected_result_type PASSED [ 92%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_success FAILED [ 93%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_success PASSED [ 93%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_single_result PASSED [ 94%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_get_model_info PASSED [ 95%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_get_model_info_cuda_available PASSED [ 96%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_empty_result PASSED [ 96%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_none_result PASSED [ 97%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_empty_results PASSED [ 98%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_sync_mixed_result_types PASSED [ 99%]
tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_sync_unknown_label PASSED [100%]

=================================== FAILURES ===================================
______ test_health_check_when_model_missing_returns_503_and_error_message ______

    def test_health_check_when_model_missing_returns_503_and_error_message():
        """UNIVERSAL test for maximum coverage."""
        # model None should cause health endpoint to raise HTTPException handled by handler
        main.model = None
        r = client.get("/health")
        assert r.status_code == 503
        j = r.json()
        # The http exception handler wraps error under "error"
>       assert "error" in j and "Model not loaded" in j["error"]
E       AssertionError: assert ('error' in {'error': 'Health check failed: ', 'path': '/health', 'status_code': 503, 'timestamp': 1763055154.2869818} and 'Model not loaded' in 'Health check failed: ')

tests/generated/test_e2e_20251113_172726_01.py:145: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    app.main:main.py:229 Health check failed:
________________ test_model_info_returns_info_when_model_loaded ________________

self = MemoryObjectReceiveStream(_state=MemoryObjectStreamState(max_buffer_size=0, buffer=deque([]), open_send_channels=0, open_receive_channels=1, waiting_receivers=OrderedDict(), waiting_senders=OrderedDict()), _closed=False)

    async def receive(self) -> T_co:
        await checkpoint()
        try:
>           return self.receive_nowait()

venv/lib/python3.12/site-packages/anyio/streams/memory.py:98: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MemoryObjectReceiveStream(_state=MemoryObjectStreamState(max_buffer_size=0, buffer=deque([]), open_send_channels=0, open_receive_channels=1, waiting_receivers=OrderedDict(), waiting_senders=OrderedDict()), _closed=False)

    def receive_nowait(self) -> T_co:
        """
        Receive the next item if it can be done without waiting.
    
        :return: the received item
        :raises ~anyio.ClosedResourceError: if this send stream has been closed
        :raises ~anyio.EndOfStream: if the buffer is empty and this stream has been
            closed from the sending end
        :raises ~anyio.WouldBlock: if there are no items in the buffer and no tasks
            waiting to send
    
        """
        if self._closed:
            raise ClosedResourceError
    
        if self._state.waiting_senders:
            # Get the item from the next sender
            send_event, item = self._state.waiting_senders.popitem(last=False)
            self._state.buffer.append(item)
            send_event.set()
    
        if self._state.buffer:
            return self._state.buffer.popleft()
        elif not self._state.open_send_channels:
            raise EndOfStream
    
>       raise WouldBlock
E       anyio.WouldBlock

venv/lib/python3.12/site-packages/anyio/streams/memory.py:93: WouldBlock

During handling of the above exception, another exception occurred:

request = <starlette.requests.Request object at 0x79444b903e00>

    async def call_next(request: Request) -> Response:
        app_exc: typing.Optional[Exception] = None
        send_stream, recv_stream = anyio.create_memory_object_stream()
    
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: typing.Callable[[], typing.Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(request.receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def close_recv_stream_on_response_sent() -> None:
            await response_sent.wait()
            recv_stream.close()
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            async with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(close_recv_stream_on_response_sent)
        task_group.start_soon(coro)
    
        try:
>           message = await recv_stream.receive()

venv/lib/python3.12/site-packages/starlette/middleware/base.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MemoryObjectReceiveStream(_state=MemoryObjectStreamState(max_buffer_size=0, buffer=deque([]), open_send_channels=0, open_receive_channels=1, waiting_receivers=OrderedDict(), waiting_senders=OrderedDict()), _closed=False)

    async def receive(self) -> T_co:
        await checkpoint()
        try:
            return self.receive_nowait()
        except WouldBlock:
            # Add ourselves in the queue
            receive_event = Event()
            container: list[T_co] = []
            self._state.waiting_receivers[receive_event] = container
    
            try:
                await receive_event.wait()
            except get_cancelled_exc_class():
                # Ignore the immediate cancellation if we already received an item, so as not to
                # lose it
                if not container:
                    raise
            finally:
                self._state.waiting_receivers.pop(receive_event, None)
    
            if container:
                return container[0]
            else:
>               raise EndOfStream
E               anyio.EndOfStream

venv/lib/python3.12/site-packages/anyio/streams/memory.py:118: EndOfStream

During handling of the above exception, another exception occurred:

    def test_model_info_returns_info_when_model_loaded():
        """UNIVERSAL test for maximum coverage."""
        info = {"name": "my-model", "version": "9.9"}
        stub = create_model_stub(is_loaded=True, predict_result={}, info=info)
        main.model = stub
>       r = client.get("/model/info")

tests/generated/test_e2e_20251113_172726_01.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/starlette/testclient.py:499: in get
    return super().get(
venv/lib/python3.12/site-packages/httpx/_client.py:1041: in get
    return self.request(
venv/lib/python3.12/site-packages/starlette/testclient.py:465: in request
    return super().request(
venv/lib/python3.12/site-packages/httpx/_client.py:814: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
venv/lib/python3.12/site-packages/httpx/_client.py:901: in send
    response = self._send_handling_auth(
venv/lib/python3.12/site-packages/httpx/_client.py:929: in _send_handling_auth
    response = self._send_handling_redirects(
venv/lib/python3.12/site-packages/httpx/_client.py:966: in _send_handling_redirects
    response = self._send_single_request(request)
venv/lib/python3.12/site-packages/httpx/_client.py:1002: in _send_single_request
    response = transport.handle_request(request)
venv/lib/python3.12/site-packages/starlette/testclient.py:342: in handle_request
    raise exc
venv/lib/python3.12/site-packages/starlette/testclient.py:339: in handle_request
    portal.call(self.app, scope, receive, send)
venv/lib/python3.12/site-packages/anyio/from_thread.py:277: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
/usr/lib/python3.12/concurrent/futures/_base.py:456: in result
    return self.__get_result()
/usr/lib/python3.12/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
venv/lib/python3.12/site-packages/anyio/from_thread.py:217: in _call_func
    retval = await retval
venv/lib/python3.12/site-packages/fastapi/applications.py:1106: in __call__
    await super().__call__(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/applications.py:122: in __call__
    await self.middleware_stack(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/errors.py:184: in __call__
    raise exc
venv/lib/python3.12/site-packages/starlette/middleware/errors.py:162: in __call__
    await self.app(scope, receive, _send)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:108: in __call__
    response = await self.dispatch_func(request, call_next)
../../test-repos/clinic/app/middleware.py:176: in dispatch
    response = await call_next(request)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:84: in call_next
    raise app_exc
venv/lib/python3.12/site-packages/starlette/middleware/base.py:70: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:108: in __call__
    response = await self.dispatch_func(request, call_next)
../../test-repos/clinic/app/middleware.py:128: in dispatch
    response = await call_next(request)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:84: in call_next
    raise app_exc
venv/lib/python3.12/site-packages/starlette/middleware/base.py:70: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
venv/lib/python3.12/site-packages/starlette/middleware/gzip.py:24: in __call__
    await responder(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/gzip.py:44: in __call__
    await self.app(scope, receive, self.send_with_gzip)
venv/lib/python3.12/site-packages/starlette/middleware/cors.py:83: in __call__
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/trustedhost.py:34: in __call__
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:108: in __call__
    response = await self.dispatch_func(request, call_next)
../../test-repos/clinic/app/middleware.py:30: in dispatch
    response = await call_next(request)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:84: in call_next
    raise app_exc
venv/lib/python3.12/site-packages/starlette/middleware/base.py:70: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:79: in __call__
    raise exc
venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:68: in __call__
    await self.app(scope, receive, sender)
venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py:20: in __call__
    raise e
venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py:17: in __call__
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/routing.py:718: in __call__
    await route.handle(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/routing.py:276: in handle
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/routing.py:66: in app
    response = await func(request)
venv/lib/python3.12/site-packages/fastapi/routing.py:274: in app
    raw_response = await run_endpoint_function(
venv/lib/python3.12/site-packages/fastapi/routing.py:191: in run_endpoint_function
    return await dependant.call(**values)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @app.get(
        "/model/info",
        response_model=ModelInfoResponse,
        tags=["Model"],
        dependencies=[Depends(verify_api_key)] if os.getenv("REQUIRE_API_KEY") else [],
    )
    async def model_info() -> ModelInfoResponse:
        """Get detailed model information"""
        if not model or not model.is_loaded():
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail="Model not loaded"
            )
    
>       return ModelInfoResponse(**model.get_model_info())
E       pydantic_core._pydantic_core.ValidationError: 5 validation errors for ModelInfoResponse
E       model_name
E         Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.5/v/missing
E       device
E         Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.5/v/missing
E       loaded
E         Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.5/v/missing
E       labels
E         Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.5/v/missing
E       cuda_available
E         Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.5/v/missing

../../test-repos/clinic/app/main.py:257: ValidationError
------------------------------ Captured log call -------------------------------
ERROR    app.middleware:middleware.py:148 {"event": "request_failed", "request_id": "req-1763055155550", "error": "5 validation errors for ModelInfoResponse\nmodel_name\n  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing\ndevice\n  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing\nloaded\n  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing\nlabels\n  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing\ncuda_available\n  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing", "duration_ms": 1.6803741455078125, "timestamp": 1763055155.552373}
ERROR    app.main:main.py:540 Unhandled exception: 5 validation errors for ModelInfoResponse
model_name
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
device
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
loaded
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
labels
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
cuda_available
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
Traceback (most recent call last):
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/anyio/streams/memory.py", line 98, in receive
    return self.receive_nowait()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/anyio/streams/memory.py", line 93, in receive_nowait
    raise WouldBlock
anyio.WouldBlock

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 78, in call_next
    message = await recv_stream.receive()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/anyio/streams/memory.py", line 118, in receive
    raise EndOfStream
anyio.EndOfStream

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 108, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/middleware.py", line 176, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 84, in call_next
    raise app_exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 70, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 108, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/middleware.py", line 128, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 84, in call_next
    raise app_exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 70, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/gzip.py", line 24, in __call__
    await responder(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/gzip.py", line 44, in __call__
    await self.app(scope, receive, self.send_with_gzip)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/cors.py", line 83, in __call__
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/trustedhost.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 108, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/middleware.py", line 30, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 84, in call_next
    raise app_exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 70, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 79, in __call__
    raise exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 68, in __call__
    await self.app(scope, receive, sender)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py", line 20, in __call__
    raise e
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py", line 17, in __call__
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/routing.py", line 718, in __call__
    await route.handle(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/routing.py", line 276, in handle
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/routing.py", line 66, in app
    response = await func(request)
               ^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/routing.py", line 274, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/main.py", line 257, in model_info
    return ModelInfoResponse(**model.get_model_info())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/pydantic/main.py", line 164, in __init__
    __pydantic_self__.__pydantic_validator__.validate_python(data, self_instance=__pydantic_self__)
pydantic_core._pydantic_core.ValidationError: 5 validation errors for ModelInfoResponse
model_name
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
device
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
loaded
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
labels
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
cuda_available
  Field required [type=missing, input_value={'name': 'my-model', 'version': '9.9'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.5/v/missing
_____________ test_health_check_returns_503_when_model_not_loaded ______________

    def test_health_check_returns_503_when_model_not_loaded():
        """UNIVERSAL test for maximum coverage."""
        """
        Hit health_check path where model is None. This should raise HTTPException
        and be converted by http_exception_handler into a JSON response with 503.
        """
        client = TestClient(app_module.app)
        # Ensure no model loaded
        with TempModelContext(None):
            resp = client.get("/health")
            assert resp.status_code == 503
            body = resp.json()
            # handler wraps error details under "error"
>           assert "Model not loaded" in body.get("error", "") or "Model not loaded" in body.get("error", "") or "Model not loaded" in str(body.get("error", ""))
E           AssertionError: assert ('Model not loaded' in 'Health check failed: ' or 'Model not loaded' in 'Health check failed: ' or 'Model not loaded' in 'Health check failed: ')
E            +  where 'Health check failed: ' = <built-in method get of dict object at 0x79444a4f3e40>('error', '')
E            +    where <built-in method get of dict object at 0x79444a4f3e40> = {'error': 'Health check failed: ', 'path': '/health', 'status_code': 503, 'timestamp': 1763055156.6618211}.get
E            +  and   'Health check failed: ' = <built-in method get of dict object at 0x79444a4f3e40>('error', '')
E            +    where <built-in method get of dict object at 0x79444a4f3e40> = {'error': 'Health check failed: ', 'path': '/health', 'status_code': 503, 'timestamp': 1763055156.6618211}.get
E            +  and   'Health check failed: ' = str('Health check failed: ')
E            +    where 'Health check failed: ' = <built-in method get of dict object at 0x79444a4f3e40>('error', '')
E            +      where <built-in method get of dict object at 0x79444a4f3e40> = {'error': 'Health check failed: ', 'path': '/health', 'status_code': 503, 'timestamp': 1763055156.6618211}.get

tests/generated/test_integ_20251113_172726_01.py:139: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    app.main:main.py:229 Health check failed:
____ test_model_info_triggers_general_exception_handler_on_unexpected_error ____

self = MemoryObjectReceiveStream(_state=MemoryObjectStreamState(max_buffer_size=0, buffer=deque([]), open_send_channels=0, open_receive_channels=1, waiting_receivers=OrderedDict(), waiting_senders=OrderedDict()), _closed=False)

    async def receive(self) -> T_co:
        await checkpoint()
        try:
>           return self.receive_nowait()

venv/lib/python3.12/site-packages/anyio/streams/memory.py:98: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MemoryObjectReceiveStream(_state=MemoryObjectStreamState(max_buffer_size=0, buffer=deque([]), open_send_channels=0, open_receive_channels=1, waiting_receivers=OrderedDict(), waiting_senders=OrderedDict()), _closed=False)

    def receive_nowait(self) -> T_co:
        """
        Receive the next item if it can be done without waiting.
    
        :return: the received item
        :raises ~anyio.ClosedResourceError: if this send stream has been closed
        :raises ~anyio.EndOfStream: if the buffer is empty and this stream has been
            closed from the sending end
        :raises ~anyio.WouldBlock: if there are no items in the buffer and no tasks
            waiting to send
    
        """
        if self._closed:
            raise ClosedResourceError
    
        if self._state.waiting_senders:
            # Get the item from the next sender
            send_event, item = self._state.waiting_senders.popitem(last=False)
            self._state.buffer.append(item)
            send_event.set()
    
        if self._state.buffer:
            return self._state.buffer.popleft()
        elif not self._state.open_send_channels:
            raise EndOfStream
    
>       raise WouldBlock
E       anyio.WouldBlock

venv/lib/python3.12/site-packages/anyio/streams/memory.py:93: WouldBlock

During handling of the above exception, another exception occurred:

request = <starlette.requests.Request object at 0x79444b9fa5a0>

    async def call_next(request: Request) -> Response:
        app_exc: typing.Optional[Exception] = None
        send_stream, recv_stream = anyio.create_memory_object_stream()
    
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: typing.Callable[[], typing.Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(request.receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def close_recv_stream_on_response_sent() -> None:
            await response_sent.wait()
            recv_stream.close()
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            async with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(close_recv_stream_on_response_sent)
        task_group.start_soon(coro)
    
        try:
>           message = await recv_stream.receive()

venv/lib/python3.12/site-packages/starlette/middleware/base.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MemoryObjectReceiveStream(_state=MemoryObjectStreamState(max_buffer_size=0, buffer=deque([]), open_send_channels=0, open_receive_channels=1, waiting_receivers=OrderedDict(), waiting_senders=OrderedDict()), _closed=False)

    async def receive(self) -> T_co:
        await checkpoint()
        try:
            return self.receive_nowait()
        except WouldBlock:
            # Add ourselves in the queue
            receive_event = Event()
            container: list[T_co] = []
            self._state.waiting_receivers[receive_event] = container
    
            try:
                await receive_event.wait()
            except get_cancelled_exc_class():
                # Ignore the immediate cancellation if we already received an item, so as not to
                # lose it
                if not container:
                    raise
            finally:
                self._state.waiting_receivers.pop(receive_event, None)
    
            if container:
                return container[0]
            else:
>               raise EndOfStream
E               anyio.EndOfStream

venv/lib/python3.12/site-packages/anyio/streams/memory.py:118: EndOfStream

During handling of the above exception, another exception occurred:

    def test_model_info_triggers_general_exception_handler_on_unexpected_error():
        """UNIVERSAL test for maximum coverage."""
        """
        If model.is_loaded raises an unexpected exception, the general exception handler
        should catch it and return a 500 JSON response ("Internal server error").
        This targets the general_exception_handler uncovered lines.
        """
        class BrokenModel:
            def is_loaded(self):
                raise RuntimeError("unexpected failure in is_loaded")
    
        client = TestClient(app_module.app)
        with TempModelContext(BrokenModel()):
>           resp = client.get("/model/info")

tests/generated/test_integ_20251113_172726_01.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
venv/lib/python3.12/site-packages/starlette/testclient.py:499: in get
    return super().get(
venv/lib/python3.12/site-packages/httpx/_client.py:1041: in get
    return self.request(
venv/lib/python3.12/site-packages/starlette/testclient.py:465: in request
    return super().request(
venv/lib/python3.12/site-packages/httpx/_client.py:814: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
venv/lib/python3.12/site-packages/httpx/_client.py:901: in send
    response = self._send_handling_auth(
venv/lib/python3.12/site-packages/httpx/_client.py:929: in _send_handling_auth
    response = self._send_handling_redirects(
venv/lib/python3.12/site-packages/httpx/_client.py:966: in _send_handling_redirects
    response = self._send_single_request(request)
venv/lib/python3.12/site-packages/httpx/_client.py:1002: in _send_single_request
    response = transport.handle_request(request)
venv/lib/python3.12/site-packages/starlette/testclient.py:342: in handle_request
    raise exc
venv/lib/python3.12/site-packages/starlette/testclient.py:339: in handle_request
    portal.call(self.app, scope, receive, send)
venv/lib/python3.12/site-packages/anyio/from_thread.py:277: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
/usr/lib/python3.12/concurrent/futures/_base.py:456: in result
    return self.__get_result()
/usr/lib/python3.12/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
venv/lib/python3.12/site-packages/anyio/from_thread.py:217: in _call_func
    retval = await retval
venv/lib/python3.12/site-packages/fastapi/applications.py:1106: in __call__
    await super().__call__(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/applications.py:122: in __call__
    await self.middleware_stack(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/errors.py:184: in __call__
    raise exc
venv/lib/python3.12/site-packages/starlette/middleware/errors.py:162: in __call__
    await self.app(scope, receive, _send)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:108: in __call__
    response = await self.dispatch_func(request, call_next)
../../test-repos/clinic/app/middleware.py:176: in dispatch
    response = await call_next(request)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:84: in call_next
    raise app_exc
venv/lib/python3.12/site-packages/starlette/middleware/base.py:70: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:108: in __call__
    response = await self.dispatch_func(request, call_next)
../../test-repos/clinic/app/middleware.py:128: in dispatch
    response = await call_next(request)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:84: in call_next
    raise app_exc
venv/lib/python3.12/site-packages/starlette/middleware/base.py:70: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
venv/lib/python3.12/site-packages/starlette/middleware/gzip.py:24: in __call__
    await responder(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/gzip.py:44: in __call__
    await self.app(scope, receive, self.send_with_gzip)
venv/lib/python3.12/site-packages/starlette/middleware/cors.py:83: in __call__
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/trustedhost.py:34: in __call__
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:108: in __call__
    response = await self.dispatch_func(request, call_next)
../../test-repos/clinic/app/middleware.py:30: in dispatch
    response = await call_next(request)
venv/lib/python3.12/site-packages/starlette/middleware/base.py:84: in call_next
    raise app_exc
venv/lib/python3.12/site-packages/starlette/middleware/base.py:70: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:79: in __call__
    raise exc
venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:68: in __call__
    await self.app(scope, receive, sender)
venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py:20: in __call__
    raise e
venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py:17: in __call__
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/routing.py:718: in __call__
    await route.handle(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/routing.py:276: in handle
    await self.app(scope, receive, send)
venv/lib/python3.12/site-packages/starlette/routing.py:66: in app
    response = await func(request)
venv/lib/python3.12/site-packages/fastapi/routing.py:274: in app
    raw_response = await run_endpoint_function(
venv/lib/python3.12/site-packages/fastapi/routing.py:191: in run_endpoint_function
    return await dependant.call(**values)
../../test-repos/clinic/app/main.py:252: in model_info
    if not model or not model.is_loaded():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <test_integ_20251113_172726_01.test_model_info_triggers_general_exception_handler_on_unexpected_error.<locals>.BrokenModel object at 0x79444b9faf30>

    def is_loaded(self):
>       raise RuntimeError("unexpected failure in is_loaded")
E       RuntimeError: unexpected failure in is_loaded

tests/generated/test_integ_20251113_172726_01.py:165: RuntimeError
------------------------------ Captured log call -------------------------------
ERROR    app.middleware:middleware.py:148 {"event": "request_failed", "request_id": "req-1763055156714", "error": "unexpected failure in is_loaded", "duration_ms": 1.3599395751953125, "timestamp": 1763055156.7154639}
ERROR    app.main:main.py:540 Unhandled exception: unexpected failure in is_loaded
Traceback (most recent call last):
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/anyio/streams/memory.py", line 98, in receive
    return self.receive_nowait()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/anyio/streams/memory.py", line 93, in receive_nowait
    raise WouldBlock
anyio.WouldBlock

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 78, in call_next
    message = await recv_stream.receive()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/anyio/streams/memory.py", line 118, in receive
    raise EndOfStream
anyio.EndOfStream

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 108, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/middleware.py", line 176, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 84, in call_next
    raise app_exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 70, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 108, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/middleware.py", line 128, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 84, in call_next
    raise app_exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 70, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/gzip.py", line 24, in __call__
    await responder(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/gzip.py", line 44, in __call__
    await self.app(scope, receive, self.send_with_gzip)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/cors.py", line 83, in __call__
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/trustedhost.py", line 34, in __call__
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 108, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/middleware.py", line 30, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 84, in call_next
    raise app_exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 70, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 79, in __call__
    raise exc
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 68, in __call__
    await self.app(scope, receive, sender)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py", line 20, in __call__
    raise e
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py", line 17, in __call__
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/routing.py", line 718, in __call__
    await route.handle(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/routing.py", line 276, in handle
    await self.app(scope, receive, send)
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/starlette/routing.py", line 66, in app
    response = await func(request)
               ^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/routing.py", line 274, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/test-repos/clinic/app/main.py", line 252, in model_info
    if not model or not model.is_loaded():
                        ^^^^^^^^^^^^^^^^^
  File "/home/sigmoid/TECH_DEMO/new-tech-demo/tests/generated/test_integ_20251113_172726_01.py", line 165, in is_loaded
    raise RuntimeError("unexpected failure in is_loaded")
RuntimeError: unexpected failure in is_loaded
_____________ TestVerifyAPIKey.test_verify_api_key_health_endpoint _____________

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a87410>
auth_client = <starlette.testclient.TestClient object at 0x79444a3d9fa0>

    def test_verify_api_key_health_endpoint(self, auth_client):
        """Test that health endpoint doesn't require API key"""
        response = auth_client.get("/health")
>       assert response.status_code == 200
E       assert 503 == 200
E        +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:55: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    app.main:main.py:229 Health check failed:
____________ TestVerifyAPIKey.test_verify_api_key_no_keys_required _____________

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a9c1d0>
auth_client = <starlette.testclient.TestClient object at 0x79444a3bdcd0>

    def test_verify_api_key_no_keys_required(self, auth_client):
        """Test endpoints when no API keys are required"""
        with patch.dict(os.environ, {"API_KEYS": "", "REQUIRE_API_KEY": "false"}):
            response = auth_client.get("/model/info")
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:71: AssertionError
__________ TestVerifyAPIKey.test_verify_api_key_missing_from_request ___________

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a9c530>
auth_client = <starlette.testclient.TestClient object at 0x79444ba0e840>

    def test_verify_api_key_missing_from_request(self, auth_client):
        """Test API key verification when key is missing"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get("/model/info")
>           assert response.status_code == 401
E           assert 503 == 401
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:79: AssertionError
_________________ TestVerifyAPIKey.test_verify_api_key_invalid _________________

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a9c890>
auth_client = <starlette.testclient.TestClient object at 0x79444a3cf080>

    def test_verify_api_key_invalid(self, auth_client):
        """Test API key verification with invalid key"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get(
                "/model/info", headers={"Authorization": "Bearer invalid_key"}
            )
>           assert response.status_code == 401
E           assert 503 == 401
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:91: AssertionError
______________ TestVerifyAPIKey.test_verify_api_key_valid_bearer _______________

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a9cbf0>
auth_client = <starlette.testclient.TestClient object at 0x79444ac73860>

    def test_verify_api_key_valid_bearer(self, auth_client):
        """Test API key verification with valid Bearer token"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get(
                "/model/info", headers={"Authorization": "Bearer test_key"}
            )
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:103: AssertionError
______________ TestVerifyAPIKey.test_verify_api_key_valid_header _______________

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a9cf50>
auth_client = <starlette.testclient.TestClient object at 0x79444a33f170>

    def test_verify_api_key_valid_header(self, auth_client):
        """Test API key verification with valid X-API-Key header"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get("/model/info", headers={"X-API-Key": "test_key"})
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:111: AssertionError
____________ TestVerifyAPIKey.test_verify_api_key_valid_query_param ____________

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a9d2b0>
auth_client = <starlette.testclient.TestClient object at 0x79444a3c9430>

    def test_verify_api_key_valid_query_param(self, auth_client):
        """Test API key verification with valid query parameter"""
        with patch.dict(
            os.environ, {"API_KEYS": "test_key", "REQUIRE_API_KEY": "true"}
        ):
            response = auth_client.get("/model/info?api_key=test_key")
>           assert response.status_code == 200
E           assert 503 == 200
E            +  where 503 = <Response [503 Service Unavailable]>.status_code

tests/manual/test_auth.py:119: AssertionError
___________ TestVerifyAPIKey.test_verify_api_key_logging_invalid_key ___________

self = <MagicMock name='logger.warning' id='133334217794112'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'warning' to have been called.

/usr/lib/python3.12/unittest/mock.py:913: AssertionError

During handling of the above exception, another exception occurred:

self = <manual.test_auth.TestVerifyAPIKey object at 0x794515a9d610>

    def test_verify_api_key_logging_invalid_key(self):
        """Test that invalid API key attempts are logged"""
        # Standard library imports
        from unittest.mock import Mock
    
        from app.auth import verify_api_key
    
        with patch.dict(
            os.environ, {"API_KEYS": "valid_key", "REQUIRE_API_KEY": "true"}
        ), patch("app.auth.logger") as mock_logger:
            mock_request = Mock()
            mock_request.url.path = "/api/test"
            mock_request.client = Mock()
            mock_request.client.host = "192.168.1.1"
            mock_request.headers = {}
            mock_request.query_params = {}
    
            # This should raise an exception and log the invalid attempt
            try:
                verify_api_key(mock_request, None)
            except Exception:
                pass
    
            # Verify that warning was logged for invalid key attempt
>           mock_logger.warning.assert_called()
E           AssertionError: Expected 'warning' to have been called.

tests/manual/test_auth.py:145: AssertionError
__________ TestRequestLoggingMiddleware.test_dispatch_with_exception ___________

request = <Mock id='133334216477584'>

    async def failing_call_next(request):
>       raise Exception("Test error")
E       Exception: Test error

tests/manual/test_middleware.py:248: Exception

During handling of the above exception, another exception occurred:

self = <app.middleware.RequestLoggingMiddleware object at 0x79444a9c0fb0>
request = <Mock id='133334216477584'>
call_next = <function TestRequestLoggingMiddleware.test_dispatch_with_exception.<locals>.failing_call_next at 0x79444ab33920>

    async def dispatch(
        self, request: Request, call_next: Callable[[Request], Awaitable[Response]]
    ) -> Response:
        start_time = time.time()
        request_id = request.headers.get(
            "X-Request-ID", f"req-{int(start_time * 1000)}"
        )
    
        logger.info(
            json.dumps(
                {
                    "event": "request_started",
                    "request_id": request_id,
                    "method": request.method,
                    "path": request.url.path,
                    "client_ip": self.get_client_id(request),
                    "timestamp": start_time,
                }
            )
        )
    
        try:
            response = await call_next(request)
    
            duration = time.time() - start_time
            logger.info(
                json.dumps(
                    {
                        "event": "request_completed",
                        "request_id": request_id,
                        "status_code": response.status_code,
                        "duration_ms": duration * 1000,
                        "timestamp": time.time(),
                    }
                )
            )
    
            response.headers["X-Request-ID"] = request_id
            return response
    
        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                json.dumps(
                    {
                        "event": "request_failed",
                        "request_id": request_id,
                        "error": str(e),
                        "duration_ms": duration * 1000,
>                       "timestamp": time.time(),
                    }
                )
            )

../../test-repos/clinic/app/middleware.py:155: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1134: in __call__
    return self._mock_call(*args, **kwargs)
/usr/lib/python3.12/unittest/mock.py:1138: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='time' id='133334216484496'>, args = (), kwargs = {}
effect = <list_iterator object at 0x79444a9c0bb0>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/usr/lib/python3.12/unittest/mock.py:1195: StopIteration

The above exception was the direct cause of the following exception:

self = <manual.test_middleware.TestRequestLoggingMiddleware object at 0x794515ac2840>
middleware = <app.middleware.RequestLoggingMiddleware object at 0x79444a9c0fb0>

    @pytest.mark.asyncio
    async def test_dispatch_with_exception(self, middleware):
        """Test request dispatch with exception"""
        mock_request = Mock()
        mock_request.method = "POST"
        mock_request.url.path = "/api/test"
        mock_request.headers = {}
        mock_request.client = None
    
        async def failing_call_next(request):
            raise Exception("Test error")
    
        with patch("time.time", side_effect=[1000.0, 1000.3]), patch(
            "app.middleware.logger"
        ) as mock_logger:
            with pytest.raises(Exception, match="Test error"):
>               await middleware.dispatch(mock_request, failing_call_next)
E               RuntimeError: coroutine raised StopIteration

tests/manual/test_middleware.py:254: RuntimeError

During handling of the above exception, another exception occurred:

self = <manual.test_middleware.TestRequestLoggingMiddleware object at 0x794515ac2840>
middleware = <app.middleware.RequestLoggingMiddleware object at 0x79444a9c0fb0>

    @pytest.mark.asyncio
    async def test_dispatch_with_exception(self, middleware):
        """Test request dispatch with exception"""
        mock_request = Mock()
        mock_request.method = "POST"
        mock_request.url.path = "/api/test"
        mock_request.headers = {}
        mock_request.client = None
    
        async def failing_call_next(request):
            raise Exception("Test error")
    
        with patch("time.time", side_effect=[1000.0, 1000.3]), patch(
            "app.middleware.logger"
        ) as mock_logger:
>           with pytest.raises(Exception, match="Test error"):
E           AssertionError: Regex pattern did not match.
E            Regex: 'Test error'
E            Input: 'coroutine raised StopIteration'

tests/manual/test_middleware.py:253: AssertionError
______________ TestClinicalAssertionModel.test_load_model_success ______________

self = <manual.test_model.TestClinicalAssertionModel object at 0x79444bd5b080>
mock_cuda = <MagicMock name='is_available' id='133334216597840'>
mock_pipeline = <MagicMock name='TextClassificationPipeline' id='133334216285536'>
mock_model_class = <MagicMock name='from_pretrained' id='133334216281696'>
mock_tokenizer = <MagicMock name='from_pretrained' id='133334216280112'>
model = <app.model.ClinicalAssertionModel object at 0x79444a9de5d0>

    @pytest.mark.asyncio
    @patch("app.model.AutoTokenizer.from_pretrained")
    @patch("app.model.AutoModelForSequenceClassification.from_pretrained")
    @patch("app.model.TextClassificationPipeline")
    @patch("torch.cuda.is_available")
    async def test_load_model_success(
        self, mock_cuda, mock_pipeline, mock_model_class, mock_tokenizer, model
    ):
        """Test successful model loading"""
        mock_cuda.return_value = False
    
        # Mock the model and tokenizer
        mock_model_instance = Mock()
        mock_model_class.return_value = mock_model_instance
        mock_tokenizer_instance = Mock()
        mock_tokenizer.return_value = mock_tokenizer_instance
        mock_pipeline_instance = Mock()
        mock_pipeline.return_value = mock_pipeline_instance
    
        await model.load_model()
    
        assert model.tokenizer == mock_tokenizer_instance
>       assert model.model == mock_model_instance
E       AssertionError: assert <Mock name='from_pretrained().to().to()' id='133334216485840'> == <Mock name='from_pretrained()' id='133334216592848'>
E        +  where <Mock name='from_pretrained().to().to()' id='133334216485840'> = <app.model.ClinicalAssertionModel object at 0x79444a9de5d0>.model

tests/manual/test_model.py:82: AssertionError
_______________ TestClinicalAssertionModel.test_predict_success ________________

self = <manual.test_model.TestClinicalAssertionModel object at 0x79444bd78500>
mock_loop = <MagicMock name='get_event_loop' id='133334216578912'>
model = <app.model.ClinicalAssertionModel object at 0x79444a9d9670>

    @pytest.mark.asyncio
    @patch("asyncio.get_event_loop")
    async def test_predict_success(self, mock_loop, model):
        """Test successful prediction"""
        # Setup model as loaded
        model._loaded = True
        model.model = Mock()
        model.pipeline = Mock()
    
        # Mock the pipeline result
        mock_result = {"label": "LABEL_0", "score": 0.95}
        model.pipeline.return_value = [mock_result]
    
        # Mock asyncio loop
        mock_loop_instance = Mock()
        mock_loop.return_value = mock_loop_instance
        mock_loop_instance.run_in_executor = AsyncMock(return_value=mock_result)
    
        result = await model.predict("test sentence")
    
>       assert result == {"label": "PRESENT", "score": 0.95}
E       AssertionError: assert {'label': 'LA...'score': 0.95} == {'label': 'PR...'score': 0.95}
E         Omitting 1 identical items, use -vv to show
E         Differing items:
E         {'label': 'LABEL_0'} != {'label': 'PRESENT'}
E         Full diff:
E         - {'label': 'PRESENT', 'score': 0.95}
E         ?            ^^ ^^^^
E         + {'label': 'LABEL_0', 'score': 0.95}
E         ?            ^^^ ^^^

tests/manual/test_model.py:145: AssertionError
____________ TestClinicalAssertionModel.test_predict_batch_success _____________

self = <manual.test_model.TestClinicalAssertionModel object at 0x79444bd79460>
mock_loop = <MagicMock name='get_event_loop' id='133334216579152'>
model = <app.model.ClinicalAssertionModel object at 0x79444a9d8cb0>

    @pytest.mark.asyncio
    @patch("asyncio.get_event_loop")
    async def test_predict_batch_success(self, mock_loop, model):
        """Test successful batch prediction"""
        # Setup model as loaded
        model._loaded = True
        model.model = Mock()
        model.pipeline = Mock()
    
        # Mock batch results
        mock_results = [
            [{"label": "LABEL_0", "score": 0.95}],
            [{"label": "LABEL_1", "score": 0.87}],
        ]
        model.pipeline.return_value = mock_results
    
        # Mock asyncio loop
        mock_loop_instance = Mock()
        mock_loop.return_value = mock_loop_instance
        mock_loop_instance.run_in_executor = AsyncMock(return_value=mock_results)
    
        result = await model.predict_batch(["sentence 1", "sentence 2"])
    
        expected = [
            {"label": "PRESENT", "score": 0.95},
            {"label": "ABSENT", "score": 0.87},
        ]
>       assert result == expected
E       AssertionError: assert [[{'label': '...core': 0.87}]] == [{'label': 'P...score': 0.87}]
E         At index 0 diff: [{'label': 'LABEL_0', 'score': 0.95}] != {'label': 'PRESENT', 'score': 0.95}
E         Full diff:
E         - [{'label': 'PRESENT', 'score': 0.95}, {'label': 'ABSENT', 'score': 0.87}]
E         ?             ^^ ^^^^                                - ^^
E         + [[{'label': 'LABEL_0', 'score': 0.95}], [{'label': 'LABEL_1', 'score': 0.87}]]
E         ? +            ^^^ ^^^                 +  +           +   ^^^                  +

tests/manual/test_model.py:237: AssertionError
=============================== warnings summary ===============================
venv/lib/python3.12/site-packages/transformers/utils/generic.py:441
  /home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
    _torch_pytree._register_pytree_node(

venv/lib/python3.12/site-packages/transformers/utils/generic.py:309
  /home/sigmoid/TECH_DEMO/new-tech-demo/venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
    _torch_pytree._register_pytree_node(

tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_logging_invalid_key
  /home/sigmoid/TECH_DEMO/new-tech-demo/tests/manual/test_auth.py:140: RuntimeWarning: coroutine 'verify_api_key' was never awaited
    verify_api_key(mock_request, None)
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform linux, python 3.12.3-final-0 -----------
Name                                                Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------------------------------------
/home/sigmoid/test-repos/clinic/app/__init__.py         1      0      0      0   100%
/home/sigmoid/test-repos/clinic/app/auth.py            39     15     18      2    53%   42, 47-70
/home/sigmoid/test-repos/clinic/app/main.py           154     19     16      1    87%   73-100, 160
/home/sigmoid/test-repos/clinic/app/middleware.py      92      0     14      0   100%
/home/sigmoid/test-repos/clinic/app/model.py           82      3     14      1    96%   45->48, 117-119
/home/sigmoid/test-repos/clinic/app/schemas.py         70      4     10      4    90%   37, 86, 90, 94
/home/sigmoid/test-repos/clinic/app/utils.py           49      5     12      3    87%   26-28, 39, 55, 104->108
-----------------------------------------------------------------------------------------------
TOTAL                                                 487     46     84     11    88%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml

=========================== short test summary info ============================
FAILED tests/generated/test_e2e_20251113_172726_01.py::test_health_check_when_model_missing_returns_503_and_error_message
FAILED tests/generated/test_e2e_20251113_172726_01.py::test_model_info_returns_info_when_model_loaded
FAILED tests/generated/test_integ_20251113_172726_01.py::test_health_check_returns_503_when_model_not_loaded
FAILED tests/generated/test_integ_20251113_172726_01.py::test_model_info_triggers_general_exception_handler_on_unexpected_error
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_health_endpoint
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_no_keys_required
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_missing_from_request
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_invalid
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_bearer
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_header
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_valid_query_param
FAILED tests/manual/test_auth.py::TestVerifyAPIKey::test_verify_api_key_logging_invalid_key
FAILED tests/manual/test_middleware.py::TestRequestLoggingMiddleware::test_dispatch_with_exception
FAILED tests/manual/test_model.py::TestClinicalAssertionModel::test_load_model_success
FAILED tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_success
FAILED tests/manual/test_model.py::TestClinicalAssertionModel::test_predict_batch_success
============ 16 failed, 106 passed, 7 skipped, 3 warnings in 20.31s ============

ðŸ“Š Combined Coverage Analysis:
Name                                                Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------------------------------------
/home/sigmoid/test-repos/clinic/app/__init__.py         1      0      0      0   100%
/home/sigmoid/test-repos/clinic/app/auth.py            39     15     18      2    53%   42, 47-70
/home/sigmoid/test-repos/clinic/app/main.py           157     21     18      2    86%   73-100, 160, 558-559
/home/sigmoid/test-repos/clinic/app/middleware.py      92      0     14      0   100%
/home/sigmoid/test-repos/clinic/app/model.py           82      3     14      1    96%   45->48, 117-119
/home/sigmoid/test-repos/clinic/app/schemas.py         70      4     10      4    90%   37, 86, 90, 94
/home/sigmoid/test-repos/clinic/app/utils.py           49      5     12      3    87%   26-28, 39, 55, 104->108
-----------------------------------------------------------------------------------------------
TOTAL                                                 490     48     86     12    88%

= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80
FINAL RESULTS
= =4.2 backend_code.log clinic1.log clinic-2.log clinic.log coverage_gaps.json coverage.xml feature.log flask-high-coverage-repo.log gap_based.log htmlcov local_artifacts local_pipeline-1.sh manual_test_result.json output_combined.log output.log PIPELINE_SUMMARY.md pytest.ini QUALITY_GATE_SUMMARY.md requirements.txt src test.db tests venv 80
âœ… Manual Test Coverage:   85.01%
âœ… Combined Line Coverage:      90.55%
ðŸ“ˆ Coverage Improvement:   5.54%

ðŸŽ‰ Quality Gate Passed: Coverage 90.55% â‰¥ 90%

âœ… Pipeline completed successfully!
